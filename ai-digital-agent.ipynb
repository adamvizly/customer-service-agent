{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26801,"status":"ok","timestamp":1709962907378,"user":{"displayName":"Ali Asghari","userId":"06405180276724022496"},"user_tz":-210},"id":"Tzx2ceKOKGWE","outputId":"232830b3-1a07-4bb5-f0ee-782c8eb89510"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.27.2\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}],"source":["! pip install -U accelerate\n","! pip install -U transformers"]},{"cell_type":"code","source":["import json\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","import torch.nn as nn\n","\n","# Load conversations\n","with open('conversations.json', 'r') as f:\n","    conversations = json.load(f)['conversations']\n","\n","# Preprocess conversations\n","conversation_data = []\n","for conv in conversations:\n","    messages = [msg['message'] for msg in conv['messages']]\n","    conversation_data.append('\\n'.join(messages))\n","\n","# Load knowledge base content\n","with open('knowledge-base.md', 'r') as f:\n","    knowledge_text = f.read()\n","\n","# Combine conversations and knowledge base\n","training_data = conversation_data + [knowledge_text]\n","\n","model_name = \"microsoft/DialoGPT-small\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","embedding = nn.Embedding(len(tokenizer), model.config.n_embd, padding_idx=tokenizer.pad_token_id)\n","\n","# Replace the embedding layer in the model\n","model.transformer.wte = embedding\n","\n","# Tokenize and encode training data\n","def encode_data(text):\n","    return tokenizer(text, truncation=True, padding='max_length', max_length=1024, return_tensors='pt')\n","\n","encoded_data = [encode_data(text) for text in training_data]\n","\n","# Create data collator\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    gradient_checkpointing=True,\n","    # fp16=True,\n",")\n","\n","# Create trainer\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, encoded_data):\n","        self.encoded_data = encoded_data\n","\n","    def __len__(self):\n","        return len(self.encoded_data)\n","\n","    def __getitem__(self, idx):\n","        return self.encoded_data[idx]\n","\n","dataset = CustomDataset(encoded_data)\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# Save the fine-tuned model\n","trainer.save_model('./fine_tuned_model')\n","tokenizer.save_pretrained('./tokenizer')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"pzbdmeMiu0JC","executionInfo":{"status":"ok","timestamp":1709963570618,"user_tz":-210,"elapsed":511088,"user":{"displayName":"Ali Asghari","userId":"06405180276724022496"}},"outputId":"b453f197-60bf-4312-ac0d-5f5d59fb9b3d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 05:30, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('./tokenizer/tokenizer_config.json',\n"," './tokenizer/special_tokens_map.json',\n"," './tokenizer/vocab.json',\n"," './tokenizer/merges.txt',\n"," './tokenizer/added_tokens.json',\n"," './tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import json\n","from datetime import datetime\n","\n","# Load the fine-tuned model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained('./fine_tuned_model', ignore_mismatched_sizes=True)\n","tokenizer = AutoTokenizer.from_pretrained('./tokenizer')\n","\n","# Load the live data source\n","with open('live-datasource.json', 'r') as f:\n","    live_data = json.load(f)\n","\n","def apply_knowledge_base(transaction, response):\n","    \"\"\"\n","    Apply knowledge base rules to the response based on the transaction details.\n","    \"\"\"\n","    # Check if the transaction is eligible for chargeback based on the rules\n","    transaction_date = datetime.strptime(transaction['date'], '%d-%b-%Y')\n","    if (datetime.now() - transaction_date).days > 90:\n","        return \"Sorry, chargebacks beyond 90 days are not possible.\"\n","    if transaction['amount'] > 1000:\n","        return \"Sorry, chargebacks above $1000 are not allowed.\"\n","    if transaction['2FA_authorization']:\n","        return \"Sorry, chargebacks for transactions with a valid 3D secure are not allowed.\"\n","\n","    return response\n","\n","def generate_response(input_text):\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","    output = model.generate(input_ids, max_length=512, pad_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    # Check if the user wants to request a charge back\n","    if \"charge back\" in input_text.lower():\n","        response = \"May I know the date, amount and merchant name?\"\n","        print(\"Agent:\", response)\n","        user_input = input(\"User: \")\n","        words = input_text.lower().split()\n","        amount = date = merchant = transaction = None\n","        try:\n","            amount_idx = words.index(\"amount\") + 1\n","            amount = float(words[amount_idx])\n","            date_idx = words.index(\"date\") + 2  # Assuming \"date is:\" format\n","            date = words[date_idx].replace(\"'\", \"\")\n","            merchant_idx = words.index(\"from\") + 1\n","            merchant = \" \".join(words[merchant_idx:])\n","        except (ValueError, IndexError):\n","            try:\n","                amount_idx = words.index(\"amount\") + 1\n","                amount = float(words[amount_idx])\n","                merchant_idx = words.index(\"from\") + 1\n","                merchant = words[merchant_idx]\n","                date_str = \" \".join(words[merchant_idx + 1:])\n","                date = datetime.strptime(date_str, '%B %d').replace(year=datetime.now().year).strftime('%d-%b-%Y')\n","            except (ValueError, IndexError):\n","                response = \"Sorry, I couldn't extract the transaction details from your input. Please provide the amount, date, and merchant name.\"\n","\n","        # Find the transaction based on the extracted details\n","        if amount and date and merchant:\n","            transaction = next((t for t in live_data if t['amount'] == amount or t['date'] == date or t['merchant'].lower() == merchant.lower()), None)\n","\n","        if transaction:\n","            response = apply_knowledge_base(transaction, response)\n","        else:\n","            response = \"Sorry, I could not find a matching transaction for the provided details. is there other transaction I can help you with?\"\n","\n","    return response\n","\n","# Conversation\n","greeting = \"Hi, What can I help you with?\"\n","print(\"Agent:\", greeting)\n","\n","while True:\n","    user_input = input(\"User: \")\n","\n","    if user_input.lower() in [\"exit\", \"bye\"]:\n","        print(\"Agent:\", \"Good Bye!\")\n","        break\n","\n","    response = generate_response(user_input)\n","    print(\"Agent:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"qozfrYDVyMrP","executionInfo":{"status":"error","timestamp":1709965761986,"user_tz":-210,"elapsed":56915,"user":{"displayName":"Ali Asghari","userId":"06405180276724022496"}},"outputId":"3f73d8c0-a73c-46af-8d2a-eb2c41a462c9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at ./fine_tuned_model and are newly initialized because the shapes did not match:\n","- transformer.wte.weight: found shape torch.Size([50258, 768]) in the checkpoint and torch.Size([50257, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Agent: Hi, What can I help you with?\n","User: Hi, I wish to request charge back\n","Agent: May I know the date, amount and merchant name?\n","User: The amount is 198.20 and date is: \"10-OCT-2022\" from \n","Agent: Sorry, I could not find a matching transaction for the provided details. is there other transaction I can help you with?\n","User: Yes, amount is amount 7849.90 from LG on December 12\n","Agent: Yes, amount is amount 7849.90 from LG on December 12,\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7508216f95d8>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvVIO21natzWJplwA0DkY4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}